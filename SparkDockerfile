FROM hbase:1.0
WORKDIR /root

#安装spark
ADD spark-2.1.1-bin-hadoop2.7.tgz /usr/local/
#添加scala
ADD scala-2.11.8.tgz /usr/local/
ADD apache-hive-2.1.1-bin.tar.gz /usr/local/
# 建立hadoop文件夹的软连接
RUN ln -s /usr/local/apache-hive-2.1.1-bin /usr/local/hive
#hadoop环境变量
ENV HADOOP_HOME /usr/local/hadoop-2.7.2
COPY config/* /tmp/

ENV SPARK_HOME /usr/local/spark-2.1.1-bin-hadoop2.7 
#scala环境变量
#ENV SCALA_HOME /usr/local/scala-2.11.8
#配置环境变量
ENV HIVE_HOME=/usr/local/apache-hive-2.1.1-bin
ENV PATH $HIVE_HOME/bin:$SCALA_HOME/bin:$SPARK_HOME/bin:$HADOOP_HOME/bin:$PATH

RUN mv /tmp/slaves $SPARK_HOME/conf/ && \
	mv /tmp/spark-env.sh $SPARK_HOME/conf/spark-env.sh && \
	mv /tmp/hive-env.sh $HIVE_HOME/conf/hive-env.sh  && \
    mv /tmp/hive-site.xml $HIVE_HOME/conf/hive-site.xml && \
	mv /tmp/mysql-connector-java-5.1.34.jar $HIVE_HOME/lib/mysql-connector-java-5.1.34.jar && \
	mv /tmp/initialize.sh /root/initialize.sh && \
	mv /tmp/start-all.sh /root/start-all.sh && \
	mv /tmp/runPI.sh /root/runPI.sh && \
	mkdir -p /root/hive/tmp && \
	mkdir -p /tmp/hive/resources && \
	mv /tmp/spark-defaults.conf  $SPARK_HOME/conf/spark-defaults.conf

RUN chmod 777 ~/start-all.sh && \
	chmod 777 ~/runPI.sh && \
	chmod 777 ~/initialize.sh


CMD [ "sh", "-c", "service ssh start; bash"]


